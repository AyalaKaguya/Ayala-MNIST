{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解决手写数字识别的问题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备\n",
    "\n",
    "在开始之前，我们将需要训练的数据进行打包，并使用加载器以方便排列组合。\n",
    "\n",
    "按照实训所要求的，数据分为训练数据集和比赛数据集，其中训练数据集用于构建训练数据，比赛数据集用于构建比赛提交。\n",
    "\n",
    "在开始之前，我们应当从一部分训练数据集中分出来一部分作为测试数据集，目前尚未实现这样的功能，考虑在写数据集优化的时候添加重映射来实现这个功能。在计划中采用前四分之三的部分用于训练数据集，后四分之一用于测试数据集，测试数据集不参与模型优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# 可视化日志\n",
    "writer = SummaryWriter(\".\\logs\")\n",
    "\n",
    "# 比赛数据集\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "test_data = test/255\n",
    "test_data = test_data.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    # 创建训练数据集\n",
    "    def __init__(self, path: str, train: bool = True, transform=None) -> None:\n",
    "        data_csv = pd.read_csv(path)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        # 提取训练集\n",
    "        self.label = data_csv['label']\n",
    "        data = data_csv.drop(labels=[\"label\"], axis=1)\n",
    "        # 归一化\n",
    "        data = data/255\n",
    "        # 图像重塑\n",
    "        self.data = data.values.reshape(-1, 28, 28, 1)\n",
    "        # 目标值向量化\n",
    "        self.target = nn.functional.one_hot(torch.tensor(self.label))/1\n",
    "        # 尾处理\n",
    "        self.total = len(self.label)\n",
    "        self.cut = int(self.total/4)\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if not self.train:\n",
    "            return self.cut\n",
    "        return self.total-self.cut\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if not self.train:\n",
    "            index = self.total-index-1\n",
    "        image = self.data[index]\n",
    "        label = self.label[index]\n",
    "        target = self.target[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {'image': image,\n",
    "                'label': label,\n",
    "                'target': target}\n",
    "\n",
    "\n",
    "# 数据集加载器\n",
    "test_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        path=\"./data/train.csv\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=8*8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        path=\"./data/train.csv\",\n",
    "        train=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=8*8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练前准备\n",
    "\n",
    "模型参数需要存储在本地，一些训练的参数也要准备，其中最重要的就是模型的定义，我们采用两层卷积网络和两层全连接层，损失函数使用CrossEntropy，模型优化器选用SGD。\n",
    "\n",
    "在后期调试的时候应引用tensorboard。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参数设置\n",
    "learning_rate = 0.001            # 学习率\n",
    "module_file_name = \"./module.pth\" # 模型存储\n",
    "\n",
    "# 创建模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32,64,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*64,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,10),\n",
    "            nn.Softmax(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(torch.float32)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "# GPU加速\n",
    "t_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model().to(t_device)\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss().to(t_device)\n",
    "# 优化器\n",
    "opti = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# 尝试加载本地模型\n",
    "model.load_state_dict(torch.load(module_file_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练阶段\n",
    "\n",
    "在一切准备完成之后就要对模型进行训练了，我们将数据以每组64个输入模型，同时计算64个网络来加速训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 1 loss(total,train):726.05 loss(total,test):243.88 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 2 loss(total,train):725.91 loss(total,test):243.86 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 3 loss(total,train):725.84 loss(total,test):243.85 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 4 loss(total,train):725.92 loss(total,test):243.85 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 5 loss(total,train):725.96 loss(total,test):243.84 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 6 loss(total,train):725.92 loss(total,test):243.84 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 7 loss(total,train):725.99 loss(total,test):243.83 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 8 loss(total,train):725.89 loss(total,test):243.85 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 9 loss(total,train):725.73 loss(total,test):243.84 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 10 loss(total,train):725.66 loss(total,test):243.84 accuacry(test):0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    step = 0\n",
    "    step_test = 0\n",
    "    loss_epoch = 0.0\n",
    "    loss_epoch_test = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    # 训练中\n",
    "    model.train()\n",
    "    for i_batch,batch_data in enumerate(train_loader):\n",
    "        image = batch_data['image'].to(t_device)\n",
    "        target = batch_data['target'].to(t_device)\n",
    "        if step % 10 == 0:\n",
    "            print(\"|\", end=\"\")\n",
    "        opti.zero_grad() # 优化器置零\n",
    "        output = model(image)\n",
    "        result_loss = loss(output, target)\n",
    "        result_loss.backward()\n",
    "        opti.step()\n",
    "        loss_epoch += result_loss\n",
    "        step += 1\n",
    "        \n",
    "    # 模型验证过程\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i_batch,batch_data in enumerate(test_loader):\n",
    "            image = batch_data['image'].to(t_device)\n",
    "            target = batch_data['target'].to(t_device)\n",
    "            label = batch_data['label'].to(t_device)\n",
    "            if step_test % 10 == 0:\n",
    "                print(\"¦\", end=\"\")\n",
    "\n",
    "            output = model(image)\n",
    "            result_loss = loss(output, target)\n",
    "\n",
    "            accuracy = (output.argmax(1) == label).sum()\n",
    "            total_accuracy += accuracy\n",
    "            loss_epoch_test += result_loss\n",
    "            step_test += 1\n",
    "\n",
    "    print(\"\\nepoch:\", epoch+1, \"loss(total,train):%.2f\" % loss_epoch,\n",
    "          \"loss(total,test):%.2f\" % loss_epoch_test,\n",
    "          \"accuacry(test):%.2f\" % (total_accuracy/(len(test_loader)*64)))\n",
    "    writer.add_scalar(\"Ayala-loss\", loss_epoch, epoch)\n",
    "    writer.add_scalar(\"Ayala-test-loss\", loss_epoch_test, epoch)\n",
    "    writer.add_scalar(\"Ayala-test-accuracy\",\n",
    "                      total_accuracy/(len(test_loader)*64), epoch)\n",
    "\n",
    "torch.save(model.state_dict(), module_file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比赛提供的数据集构建提交\n",
    "\n",
    "在上一步我们初步得到了一个98%准确度的模型，我们将使用这个模型并对比赛进行提交。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28, 28)),\n",
    "])\n",
    "\n",
    "idx = []\n",
    "ans = []\n",
    "\n",
    "for index, image in enumerate(test_data):\n",
    "    image = transform(image)\n",
    "    image = torch.reshape(image, (1, 1, 28, 28))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        target = int(output.argmax(1))\n",
    "        idx.append(index+1)\n",
    "        ans.append(target)\n",
    "        \n",
    "frame = pd.DataFrame({'ImageId':idx,'Label':ans})\n",
    "frame.to_csv(\"./submission.csv\",index=False,sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "✨差不多结束了，你可以在Kaggle上提交了🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
