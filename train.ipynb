{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è§£å†³æ‰‹å†™æ•°å­—è¯†åˆ«çš„é—®é¢˜"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®å‡†å¤‡\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬å°†éœ€è¦è®­ç»ƒçš„æ•°æ®è¿›è¡Œæ‰“åŒ…ï¼Œå¹¶ä½¿ç”¨åŠ è½½å™¨ä»¥æ–¹ä¾¿æ’åˆ—ç»„åˆã€‚\n",
    "\n",
    "æŒ‰ç…§å®è®­æ‰€è¦æ±‚çš„ï¼Œæ•°æ®åˆ†ä¸ºè®­ç»ƒæ•°æ®é›†å’Œæ¯”èµ›æ•°æ®é›†ï¼Œå…¶ä¸­è®­ç»ƒæ•°æ®é›†ç”¨äºæ„å»ºè®­ç»ƒæ•°æ®ï¼Œæ¯”èµ›æ•°æ®é›†ç”¨äºæ„å»ºæ¯”èµ›æäº¤ã€‚\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬åº”å½“ä»ä¸€éƒ¨åˆ†è®­ç»ƒæ•°æ®é›†ä¸­åˆ†å‡ºæ¥ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•æ•°æ®é›†ï¼Œç›®å‰å°šæœªå®ç°è¿™æ ·çš„åŠŸèƒ½ï¼Œè€ƒè™‘åœ¨å†™æ•°æ®é›†ä¼˜åŒ–çš„æ—¶å€™æ·»åŠ é‡æ˜ å°„æ¥å®ç°è¿™ä¸ªåŠŸèƒ½ã€‚åœ¨è®¡åˆ’ä¸­é‡‡ç”¨å‰å››åˆ†ä¹‹ä¸‰çš„éƒ¨åˆ†ç”¨äºè®­ç»ƒæ•°æ®é›†ï¼Œåå››åˆ†ä¹‹ä¸€ç”¨äºæµ‹è¯•æ•°æ®é›†ï¼Œæµ‹è¯•æ•°æ®é›†ä¸å‚ä¸æ¨¡å‹ä¼˜åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# å¯è§†åŒ–æ—¥å¿—\n",
    "writer = SummaryWriter(\".\\logs\")\n",
    "\n",
    "# æ¯”èµ›æ•°æ®é›†\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "test_data = test/255\n",
    "test_data = test_data.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†\n",
    "    def __init__(self, path: str, train: bool = True, transform=None) -> None:\n",
    "        data_csv = pd.read_csv(path)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        # æå–è®­ç»ƒé›†\n",
    "        self.label = data_csv['label']\n",
    "        data = data_csv.drop(labels=[\"label\"], axis=1)\n",
    "        # å½’ä¸€åŒ–\n",
    "        data = data/255\n",
    "        # å›¾åƒé‡å¡‘\n",
    "        self.data = data.values.reshape(-1, 28, 28, 1)\n",
    "        # ç›®æ ‡å€¼å‘é‡åŒ–\n",
    "        self.target = nn.functional.one_hot(torch.tensor(self.label))/1\n",
    "        # å°¾å¤„ç†\n",
    "        self.total = len(self.label)\n",
    "        self.cut = int(self.total/4)\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if not self.train:\n",
    "            return self.cut\n",
    "        return self.total-self.cut\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if not self.train:\n",
    "            index = self.total-index-1\n",
    "        image = self.data[index]\n",
    "        label = self.label[index]\n",
    "        target = self.target[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {'image': image,\n",
    "                'label': label,\n",
    "                'target': target}\n",
    "\n",
    "\n",
    "# æ•°æ®é›†åŠ è½½å™¨\n",
    "test_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        path=\"./data/train.csv\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=8*8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        path=\"./data/train.csv\",\n",
    "        train=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=8*8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡å‹è®­ç»ƒå‰å‡†å¤‡\n",
    "\n",
    "æ¨¡å‹å‚æ•°éœ€è¦å­˜å‚¨åœ¨æœ¬åœ°ï¼Œä¸€äº›è®­ç»ƒçš„å‚æ•°ä¹Ÿè¦å‡†å¤‡ï¼Œå…¶ä¸­æœ€é‡è¦çš„å°±æ˜¯æ¨¡å‹çš„å®šä¹‰ï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸¤å±‚å·ç§¯ç½‘ç»œå’Œä¸¤å±‚å…¨è¿æ¥å±‚ï¼ŒæŸå¤±å‡½æ•°ä½¿ç”¨CrossEntropyï¼Œæ¨¡å‹ä¼˜åŒ–å™¨é€‰ç”¨SGDã€‚\n",
    "\n",
    "åœ¨åæœŸè°ƒè¯•çš„æ—¶å€™åº”å¼•ç”¨tensorboardã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å‚æ•°è®¾ç½®\n",
    "learning_rate = 0.001            # å­¦ä¹ ç‡\n",
    "module_file_name = \"./module.pth\" # æ¨¡å‹å­˜å‚¨\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32,64,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*64,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,10),\n",
    "            nn.Softmax(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(torch.float32)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "# GPUåŠ é€Ÿ\n",
    "t_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model().to(t_device)\n",
    "# æŸå¤±å‡½æ•°\n",
    "loss = nn.CrossEntropyLoss().to(t_device)\n",
    "# ä¼˜åŒ–å™¨\n",
    "opti = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# å°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹\n",
    "model.load_state_dict(torch.load(module_file_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è®­ç»ƒé˜¶æ®µ\n",
    "\n",
    "åœ¨ä¸€åˆ‡å‡†å¤‡å®Œæˆä¹‹åå°±è¦å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒäº†ï¼Œæˆ‘ä»¬å°†æ•°æ®ä»¥æ¯ç»„64ä¸ªè¾“å…¥æ¨¡å‹ï¼ŒåŒæ—¶è®¡ç®—64ä¸ªç½‘ç»œæ¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 1 loss(total,train):726.05 loss(total,test):243.88 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 2 loss(total,train):725.91 loss(total,test):243.86 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 3 loss(total,train):725.84 loss(total,test):243.85 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 4 loss(total,train):725.92 loss(total,test):243.85 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 5 loss(total,train):725.96 loss(total,test):243.84 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 6 loss(total,train):725.92 loss(total,test):243.84 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 7 loss(total,train):725.99 loss(total,test):243.83 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 8 loss(total,train):725.89 loss(total,test):243.85 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 9 loss(total,train):725.73 loss(total,test):243.84 accuacry(test):0.98\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦Â¦\n",
      "epoch: 10 loss(total,train):725.66 loss(total,test):243.84 accuacry(test):0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    step = 0\n",
    "    step_test = 0\n",
    "    loss_epoch = 0.0\n",
    "    loss_epoch_test = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    # è®­ç»ƒä¸­\n",
    "    model.train()\n",
    "    for i_batch,batch_data in enumerate(train_loader):\n",
    "        image = batch_data['image'].to(t_device)\n",
    "        target = batch_data['target'].to(t_device)\n",
    "        if step % 10 == 0:\n",
    "            print(\"|\", end=\"\")\n",
    "        opti.zero_grad() # ä¼˜åŒ–å™¨ç½®é›¶\n",
    "        output = model(image)\n",
    "        result_loss = loss(output, target)\n",
    "        result_loss.backward()\n",
    "        opti.step()\n",
    "        loss_epoch += result_loss\n",
    "        step += 1\n",
    "        \n",
    "    # æ¨¡å‹éªŒè¯è¿‡ç¨‹\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i_batch,batch_data in enumerate(test_loader):\n",
    "            image = batch_data['image'].to(t_device)\n",
    "            target = batch_data['target'].to(t_device)\n",
    "            label = batch_data['label'].to(t_device)\n",
    "            if step_test % 10 == 0:\n",
    "                print(\"Â¦\", end=\"\")\n",
    "\n",
    "            output = model(image)\n",
    "            result_loss = loss(output, target)\n",
    "\n",
    "            accuracy = (output.argmax(1) == label).sum()\n",
    "            total_accuracy += accuracy\n",
    "            loss_epoch_test += result_loss\n",
    "            step_test += 1\n",
    "\n",
    "    print(\"\\nepoch:\", epoch+1, \"loss(total,train):%.2f\" % loss_epoch,\n",
    "          \"loss(total,test):%.2f\" % loss_epoch_test,\n",
    "          \"accuacry(test):%.2f\" % (total_accuracy/(len(test_loader)*64)))\n",
    "    writer.add_scalar(\"Ayala-loss\", loss_epoch, epoch)\n",
    "    writer.add_scalar(\"Ayala-test-loss\", loss_epoch_test, epoch)\n",
    "    writer.add_scalar(\"Ayala-test-accuracy\",\n",
    "                      total_accuracy/(len(test_loader)*64), epoch)\n",
    "\n",
    "torch.save(model.state_dict(), module_file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯¹æ¯”èµ›æä¾›çš„æ•°æ®é›†æ„å»ºæäº¤\n",
    "\n",
    "åœ¨ä¸Šä¸€æ­¥æˆ‘ä»¬åˆæ­¥å¾—åˆ°äº†ä¸€ä¸ª98%å‡†ç¡®åº¦çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªæ¨¡å‹å¹¶å¯¹æ¯”èµ›è¿›è¡Œæäº¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28, 28)),\n",
    "])\n",
    "\n",
    "idx = []\n",
    "ans = []\n",
    "\n",
    "for index, image in enumerate(test_data):\n",
    "    image = transform(image)\n",
    "    image = torch.reshape(image, (1, 1, 28, 28))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        target = int(output.argmax(1))\n",
    "        idx.append(index+1)\n",
    "        ans.append(target)\n",
    "        \n",
    "frame = pd.DataFrame({'ImageId':idx,'Label':ans})\n",
    "frame.to_csv(\"./submission.csv\",index=False,sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "âœ¨å·®ä¸å¤šç»“æŸäº†ï¼Œä½ å¯ä»¥åœ¨Kaggleä¸Šæäº¤äº†ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
