{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解决手写数字识别的问题 - 数据处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### ✔ 提前说明\n",
    ">\n",
    "> 为了将本文用于实训报告的书写，特将模块引入分散到了各代码块中，实际上这样做是坏文明\n",
    "\n",
    "本篇文章只是对于该问题的一个简单处理和对代码的基本解释，集合度更高的在另一篇[NoteBook](./train.ipynb)中。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、数据的读取与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_csv = pd.read_csv(\"./data/train.csv\")\n",
    "# 提取训练集\n",
    "train_label = train_csv['label']\n",
    "train_data = train_csv.drop(labels=[\"label\"], axis=1)\n",
    "# 归一化\n",
    "train_data = train_data/255\n",
    "# 图像重塑\n",
    "train_data = train_data.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 比赛数据集\n",
    "test_csv = pd.read_csv(\"./data/test.csv\")\n",
    "test_data = test_csv/255\n",
    "test_data = test_data.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、展示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23f0274bf10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(train_data[114],cmap=\"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、对数据进一步的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练用数据集的大小：(42000, 28, 28, 1)\n",
      "待验证数据集的大小：(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"训练用数据集的大小：{}\".format(train_data.shape))\n",
    "print(\"待验证数据集的大小：{}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Describe\n",
      " count       785\n",
      "unique        1\n",
      "top       False\n",
      "freq        785\n",
      "dtype: object\n",
      "\n",
      "Test Data Describe\n",
      " count       784\n",
      "unique        1\n",
      "top       False\n",
      "freq        784\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data Describe\\n\",train_csv.isnull().any().describe())\n",
    "print(\"\\nTest Data Describe\\n\",test_csv.isnull().any().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "train_target = nn.functional.one_hot(torch.tensor(train_label)) # 独热编码\n",
    "train_target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    # 创建训练数据集\n",
    "    def __init__(self, path: str, train: bool = True, transform=None) -> None:\n",
    "        data_csv = pd.read_csv(path)\n",
    "        self.transform = transform                     # 对于数据集输出统一执行的Transform指令\n",
    "        self.train = train                             # 判断当前是训练集和测试集的flag\n",
    "        self.label = data_csv['label']                 # 提取label\n",
    "        data = data_csv.drop(labels=[\"label\"], axis=1) # 提取训练集\n",
    "        data = data/255                                # 归一化\n",
    "        self.data = data.values.reshape(-1, 28, 28, 1) # 图像重塑\n",
    "        self.target = nn.functional.one_hot(torch.tensor(self.label))/1 # 目标值向量化(独热编码)\n",
    "        self.total = len(self.label) # 训练用数据集的总大小\n",
    "        self.cut = int(self.total/4) # 产生一个用于分割训练用数据集的指针\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self) -> int:       # 重写了对于长度判断的逻辑\n",
    "        if not self.train:          # 当类处于测试集状态下输出测试集的长度\n",
    "            return self.cut\n",
    "        return self.total-self.cut  # 训练集状态下输出减去的长度\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if not self.train:          # 测试集从后往前输出，训练集正常输出\n",
    "            index = self.total-index-1\n",
    "        image = self.data[index]\n",
    "        label = self.label[index]\n",
    "        target = self.target[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {'image': image,\n",
    "                'label': label,\n",
    "                'target': target}\n",
    "        \n",
    "example_dataset = TrainDataset(\n",
    "    path=\"./data/train.csv\",\n",
    "    train= True,\n",
    "    transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "    ]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        path=\"./data/train.csv\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=8*8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        path=\"./data/train.csv\",\n",
    "        train=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((28, 28)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=8*8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,32,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32,64,5,padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*64,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,10),\n",
    "            nn.Softmax(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(torch.float32)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、损失函数与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# 参数设置\n",
    "learning_rate = 0.1             # 学习率\n",
    "module_file_name = \"./module-p.pth\" # 模型存储\n",
    "# GPU加速\n",
    "t_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model().to(t_device)\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss().to(t_device)\n",
    "# 优化器\n",
    "opti = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# 尝试加载本地模型\n",
    "model.load_state_dict(torch.load(module_file_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8、模型训练和训练过程优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 1 loss(total,train):939.40 loss(total,test):271.57 accuacry(test):0.82\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 2 loss(total,train):782.94 loss(total,test):252.17 accuacry(test):0.93\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 3 loss(total,train):752.92 loss(total,test):253.23 accuacry(test):0.93\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 4 loss(total,train):744.36 loss(total,test):248.68 accuacry(test):0.95\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 5 loss(total,train):739.76 loss(total,test):246.87 accuacry(test):0.96\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 6 loss(total,train):736.43 loss(total,test):250.89 accuacry(test):0.94\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 7 loss(total,train):734.55 loss(total,test):245.05 accuacry(test):0.97\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 8 loss(total,train):732.56 loss(total,test):245.72 accuacry(test):0.97\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 9 loss(total,train):731.55 loss(total,test):244.75 accuacry(test):0.97\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦\n",
      "epoch: 10 loss(total,train):730.35 loss(total,test):244.67 accuacry(test):0.97\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    step = 0\n",
    "    step_test = 0\n",
    "    # 每一轮的统计数据\n",
    "    loss_epoch = 0.0\n",
    "    loss_epoch_test = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    \n",
    "    # 训练中\n",
    "    model.train()\n",
    "    for i_batch,batch_data in enumerate(train_loader):\n",
    "        image = batch_data['image'].to(t_device)\n",
    "        target = batch_data['target'].to(t_device)\n",
    "        if step % 10 == 0:\n",
    "            print(\"|\", end=\"\")\n",
    "        opti.zero_grad() # 优化器置零\n",
    "        output = model(image)\n",
    "        result_loss = loss(output, target)\n",
    "        result_loss.backward()\n",
    "        opti.step()\n",
    "        loss_epoch += result_loss\n",
    "        step += 1\n",
    "        \n",
    "    # 模型验证过程\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i_batch,batch_data in enumerate(test_loader):\n",
    "            image = batch_data['image'].to(t_device)\n",
    "            target = batch_data['target'].to(t_device)\n",
    "            label = batch_data['label'].to(t_device)\n",
    "            if step_test % 10 == 0:\n",
    "                print(\"¦\", end=\"\")\n",
    "\n",
    "            output = model(image)\n",
    "            result_loss = loss(output, target)\n",
    "\n",
    "            accuracy = (output.argmax(1) == label).sum()\n",
    "            total_accuracy += accuracy\n",
    "            loss_epoch_test += result_loss\n",
    "            step_test += 1\n",
    "\n",
    "    print(\"\\nepoch:\", epoch+1, \"loss(total,train):%.2f\" % loss_epoch,\n",
    "          \"loss(total,test):%.2f\" % loss_epoch_test,\n",
    "          \"accuacry(test):%.2f\" % (total_accuracy/(len(test_loader)*64)))\n",
    "\n",
    "torch.save(model.state_dict(), module_file_name) # 存储训练的模型参数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9、提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28, 28)),\n",
    "])\n",
    "\n",
    "idx = []\n",
    "ans = []\n",
    "\n",
    "for index, image in enumerate(test_data):\n",
    "    image = transform(image)\n",
    "    image = torch.reshape(image, (1, 1, 28, 28))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        target = int(output.argmax(1))\n",
    "        idx.append(index+1)\n",
    "        ans.append(target)\n",
    "        \n",
    "frame = pd.DataFrame({'ImageId':idx,'Label':ans})\n",
    "frame.to_csv(\"./submission.csv\",index=False,sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10、数据增强和模型优化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分我不是很有时间弄，距离提交仅剩半个小时，大概抄下思路\n",
    "\n",
    "已下代码均不可运行，我还没来得及整理和重写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过数据增强来防止过拟合\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # 对输入的图片每个通道减去每个通道对应均值\n",
    "        samplewise_center=False,  # 每张图片减去样本均值, 使得每个样本均值为0\n",
    "        featurewise_std_normalization=False,  # 将输入除以数据集的标准差\n",
    "        samplewise_std_normalization=False,  # 将样本输入除以数据集的标准差\n",
    "        zca_whitening=False,  # 去除样本之间的相关性\n",
    "        rotation_range=10,  # 随机旋转图像（0到180度） \n",
    "        zoom_range = 0.1, # 随机缩放图像\n",
    "        width_shift_range=0.1,   # 水平随机移动图像（总宽度的一部分）\n",
    "        height_shift_range=0.1,  # 垂直随机移动图像（总高度的一部分）\n",
    "        horizontal_flip=False,  # 水平随机翻转图像\n",
    "        vertical_flip=False)  # 垂直随机翻转图像\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义自己的混淆矩阵函数\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    - cm : 计算出的混淆矩阵的值\n",
    "    - classes : 混淆矩阵中每一行每一列对应的列\n",
    "    - normalize : True:显示百分比, False:显示个数\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    # plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "Y_pred = model.predict(X_val)    # 对验证数据集进行预测\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)  # 将预测的类转换为一个热向量\n",
    "Y_true = np.argmax(Y_val, axis=1)  # 将验证集中实际观察到的类转换为一个热向量\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)  # 计算混淆矩阵\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(10))\n",
    "plt.subplot(122)\n",
    "plot_confusion_matrix(confusion_mtx, classes=range(10), normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
